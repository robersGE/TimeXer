{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/robers/projects\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "print(parent_directory)\n",
    "\n",
    "if 'TimeXer' in parent_directory:\n",
    "    # Add the parent directory to sys.path\n",
    "    sys.path.append(parent_directory)\n",
    "    os.chdir(parent_directory)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.database import connectionSQL\n",
    "import pandas as pd\n",
    "\n",
    "engine = connectionSQL(\"PROMART_PRD\", 'cfg/secrets.yaml')\n",
    "\n",
    "# query = \"\"\"\n",
    "# SELECT DISTINCT [Type_query]\n",
    "# FROM [PROMART_PRD].[dbo].[t_ML_meteoswiss_weather_forecast];\"\"\"\n",
    "\n",
    "# m_suisse_types = pd.read_sql_query(query, con=engine)\n",
    "\n",
    "# query = \"\"\"\n",
    "# SELECT DISTINCT [Type_query]\n",
    "# FROM [PROMART_PRD].[dbo].[t_ML_weather_data];\"\"\"\n",
    "\n",
    "# weather_data_types = pd.read_sql_query(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(m_suisse_types['Type_query'])\n",
    "# print(weather_data_types['Type_query'])\n",
    "m_suisse_type = 'icon_ch2_0'\n",
    "weather_data_type = 'matics-mos-flex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dropcolumns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3599571/1041584907.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \"\"\"\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Execute the query and load the results into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropcolumns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Type_query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/TimeXer/venv_TimeXer/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5898\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5899\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5900\u001b[0m         ):\n\u001b[1;32m   5901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dropcolumns'"
     ]
    }
   ],
   "source": [
    "Abbreviations = ['ABO', 'PAY']\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-01-31'\n",
    "\n",
    "# Convert the list of abbreviations into a SQL-compatible string\n",
    "abbreviation_list = \"', '\".join(Abbreviations)\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "      [Abbreviation],\n",
    "      [Delivery_date],\n",
    "      [Issue_date],\n",
    "      [Type_query],\n",
    "      [rain {{mm/h}}],\n",
    "      [temperature {{Celsius}}],\n",
    "      [relative humidity{{%}}],\n",
    "      [radiation globale {{W/m2}}]\n",
    "  FROM [PROMART_PRD].[dbo].[t_ML_weather_data]\n",
    "  WHERE [Type_query] = '{weather_data_type}' \n",
    "    AND [Abbreviation] IN ('{abbreviation_list}')\n",
    "    AND [Delivery_date] BETWEEN '{start_date}' AND '{end_date}'\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the results into a DataFrame\n",
    "df = pd.read_sql_query(query, con=engine)\n",
    "df.drop('Type_query', axis=1, inplace=True)\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2881 73\n",
      "2881 61\n"
     ]
    }
   ],
   "source": [
    "# endogenous variables: load from gb \n",
    "# exogenous variables: temperature, rain, radiation, calendar_date, day_of_week, is_holiday\n",
    "\n",
    "from utils.dataset import remove_duplicates_keep_latest\n",
    "print(len(df['Delivery_date'].unique()), len(df['Issue_date'].unique()))\n",
    "df_unique = remove_duplicates_keep_latest(df, group_cols=['Abbreviation', 'Delivery_date'], sort_col='Issue_date')\n",
    "print(len(df_unique['Delivery_date'].unique()), len(df_unique['Issue_date'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT\n",
    "      [Delivery_date],\n",
    "      [Issue_date],\n",
    "      [CMO],\n",
    "      [MAG],\n",
    "      [Bilan],\n",
    "      [Validation]\n",
    "FROM [PROMART_PRD].[dbo].[t_ML_validation_gb_consumption] \n",
    "WHERE ([Validation] = '100' OR [Validation] = '110')\n",
    "  AND [Delivery_date] BETWEEN '{start_date}' AND '{end_date}'\"\"\"\n",
    "\n",
    "df_load = pd.read_sql_query(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load_unique = remove_duplicates_keep_latest(df_load, group_cols=['Delivery_date'], sort_col='Issue_date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Abbreviation', 'Delivery_date', 'Issue_date', 'Type_query',\n",
       "       'rain {mm/h}', 'temperature {Celsius}', 'relative humidity{%}',\n",
       "       'radiation globale {W/m2}', 'Bilan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_merged.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import append_abbreviation_to_columns\n",
    "# Example columns to update\n",
    "columns_to_update = ['rain {mm/h}', 'temperature {Celsius}', 'relative humidity{%}', 'radiation globale {W/m2}']\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df_unique_noabbr = append_abbreviation_to_columns(df_unique, columns_to_update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2881\n",
      "2881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Delivery_date', 'ABO rain {mm/h}', 'ABO temperature {Celsius}',\n",
       "       'ABO relative humidity{%}', 'ABO radiation globale {W/m2}',\n",
       "       'PAY rain {mm/h}', 'PAY temperature {Celsius}',\n",
       "       'PAY relative humidity{%}', 'PAY radiation globale {W/m2}'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_unique_noabbr))\n",
    "print(len(df_unique_noabbr['Delivery_date'].unique()))\n",
    "df_unique_noabbr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both dataframes are sorted by 'Delivery_date'\n",
    "df_unique_noabbr = df_unique_noabbr.sort_values('Delivery_date')\n",
    "df_load_unique = df_load_unique.sort_values('Delivery_date')\n",
    "\n",
    "# Perform an inner merge to keep only matching 'Delivery_date' rows in both dataframes\n",
    "df_unique_merged = pd.merge(\n",
    "    df_unique_noabbr, \n",
    "    df_load_unique[['Delivery_date', 'Bilan']], \n",
    "    on='Delivery_date', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(len(df_unique_merged))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_TimeXer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
